{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to recreate the neural network predicting concrete strength development [1] based on the experimental dataset [2].\n",
    "\n",
    "Unlike in [1], I didn't divide the whole dataset into 4 subsets based on local correlation. Instead, I pick a hundred experiments from the dataset at random and use those for validation of the trained network. All other experiments are used for training the network. It turns out that this simple randomised approach needs refinement because while the error rate does converge to a fixed limit, the predicted results still differ from the experimental results sometimes quite a bit. So it appears that preprocessing the dataset and finding local correlations should help improving the accuracy. This is currently a todo. Specifically, the coefficients of determination R^2 must be at least above 0.8 in order to match the accuracy of the NN in [1].\n",
    "\n",
    "I use Python mostly for presentation reasons and because anybody can train this NN straight from GitHub with no local setup.\n",
    "\n",
    "[1] I-Cheng Yeh, [Modeling of strength of high performance concrete using artificial neural networks](https://www.researchgate.net/publication/222447231_Modeling_of_Strength_of_High-Performance_Concrete_Using_Artificial_Neural_Networks_Cement_and_Concrete_research_2812_1797-1808), _Cement and Concrete Research_, Vol. 28, No. 12, pp. 1797-1808 (1998).\n",
    "\n",
    "[2] https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import seaborn\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make `numpy` values easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from [2]. I converted it to CSV for simplicity. Then perform a random permutation on the dataset. Different runs of this program lead to different weights computed for the network because due to the random permutation the function that the NN tries to approximate is different in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(\"https://raw.githubusercontent.com/vkomenda/concrete-strength/main/concrete-dataset.csv\")\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the amounts of cement and water in the mix and their relative ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(dataset[['Cement (kg/m^3)', 'Water (kg/m^3)']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few entries after shuffling, and their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input parameters are those in the first 8 data columns (not counting the experiment indices on the left). The experimental results are in the rightmost column. These two categories are called features and labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.copy()\n",
    "labels = features.pop('Concrete compressive strength (MPa)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert features to a `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the features and labels into two parts: a 100 records for validation and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = features[-100:]\n",
    "labels_valid = labels[-100:]\n",
    "features_train = features[:-100]\n",
    "labels_train = labels[:-100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train the NN model. There are 8 input neurons. Those are connected to 32 neurons in the hidden (intermediate) layer. Those are in turn connected to a single output neuron.\n",
    "\n",
    "All connections are labelled with weights which are the values that change during training to output the closest result according to the loss function - mean squared error in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    optimizer = tf.optimizers.Adam(learning_rate = 0.001)\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    features_train,\n",
    "    labels_train,\n",
    "    epochs=40,\n",
    "    verbose=1,\n",
    "    validation_data = (\n",
    "        features_valid,\n",
    "        labels_valid\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the trained weights labelling the connections of the hidden layer neurons with the output neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].kernel.numpy().transpose()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way to access the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pandas.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a plotter function for the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 500])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Concrete compressive strength (MPa)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the losses: the training set loss and the loss on the validation set. If the loss curve starts to \"dance\" after a few epochs of relative convergence, that means the NN is overfitted on the training data. That is, it becomes too specialised on possible outliers in the training set. That means that outliers in the validation set can get misclassified as a consequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the concrete strength of the set of experiments used for validation. Those experiments weren't used for training, so the predictions shows the performance of the NN on real inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a plotter function for the difference between what was observed in the experiments and what the NN actually computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison():\n",
    "    plt.scatter(labels_valid, labels_predict)\n",
    "    plt.plot(labels[:,0], y_pred_test, 'r', label='Predicted Data')\n",
    "    plt.xlabel('strength observed in lab')\n",
    "    plt.ylabel('strength predicted by NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) R^2 which is a measure of how well the observed outcomes are replicated by the model. It was used in [1] to show that the NN was more accurate than the regression analysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_squared(y, y_pred):\n",
    "    residual = tf.math.reduce_sum(np.square(np.subtract(y, y_pred)))\n",
    "    total = tf.math.reduce_sum(np.square(np.subtract(y, tf.math.reduce_mean(y))))\n",
    "    r2 = np.subtract(1.0, np.divide(residual, total))\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the validation concrete strengths alongside the predicted ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = labels_valid.values\n",
    "y_predict = labels_predict.transpose()[0]\n",
    "\n",
    "print('validation values:\\n', y_valid)\n",
    "print('predicted values:\\n', y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R^2 of the validation set. In [1] it was greater than 0.8. Here it is lower because we didn't split the dataset into subsets based on internal correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_valid = R_squared(y_valid, y_predict)\n",
    "print('R^2 of the validation set:', r2_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
