{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to recreate the neural network predicting concrete strength development [1] based on the experimental dataset [2].\n",
    "\n",
    "Unlike in [1], I didn't divide the whole dataset into 4 subsets based on local correlation. Instead, I pick a random 3/4 of the experiments from the dataset and use those for validation of the trained network. All other experiments are used for training the network. It turns out that this simple randomised approach works with an additional hidden layer of a few neurons that model an experiment classifier whose purpose is to learn a few clusters within the training dataset. The error rate converges to a fixed limit. The predicted values are fairly correlated with the experimental results. The coefficients of determination R^2 are about 0.85 on the training set and about 0.8 on the validation set, which matches the accuracy of the NN in [1].\n",
    "\n",
    "I use Python mostly for presentation reasons and because anybody can train this NN straight from GitHub with no local setup.\n",
    "\n",
    "[1] I-Cheng Yeh, [Modeling of strength of high performance concrete using artificial neural networks](https://www.researchgate.net/publication/222447231_Modeling_of_Strength_of_High-Performance_Concrete_Using_Artificial_Neural_Networks_Cement_and_Concrete_research_2812_1797-1808), _Cement and Concrete Research_, Vol. 28, No. 12, pp. 1797-1808 (1998).\n",
    "\n",
    "[2] https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import seaborn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, backend\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make `numpy` values easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from [2]. I converted it to CSV for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(\"https://raw.githubusercontent.com/vkomenda/concrete-strength/main/concrete-dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the amounts of cement and water in the mix and their relative ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(dataset[['Cement (kg/m^3)', 'Water (kg/m^3)']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few entries after shuffling, and their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a random permutation on the dataset. Different runs of this program lead to different weights computed for the network because due to the random permutation the function that the NN tries to approximate is different in each case.\n",
    "\n",
    "Split the features and labels into two parts: a 3/4 of the records for validation and 1/4 the rest for training.\n",
    "\n",
    "The input parameters are those in the first 8 data columns (not counting the experiment indices on the left). The experimental results are in the rightmost column. These two categories are called features and labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset.sample(frac = 0.75)\n",
    "valid_set = dataset.drop(train_set.index)\n",
    "\n",
    "label_name = 'Concrete compressive strength (MPa)'\n",
    "features_train = train_set.copy()\n",
    "labels_train = features_train.pop(label_name)\n",
    "features_valid = valid_set.copy()\n",
    "labels_valid = features_valid.pop(label_name)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) R^2 which is a measure of how well the observed outcomes are replicated by the model. It was used in [1] to show that the NN was more accurate than the regression analysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_squared(y, y_pred):\n",
    "    residual = tf.math.reduce_sum(np.square(np.subtract(y, y_pred)))\n",
    "    total = tf.math.reduce_sum(np.square(np.subtract(y, tf.math.reduce_mean(y))))\n",
    "    r2 = np.subtract(1.0, np.divide(residual, total))\n",
    "    return r2\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  backend.sum(backend.square(y_true - y_pred)) \n",
    "    SS_tot = backend.sum(backend.square(y_true - backend.mean(y_true))) \n",
    "    return (1 - SS_res / (SS_tot + backend.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function can be just the distance from the ideal R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred):\n",
    "    r2 = coeff_determination(y_true, y_pred)\n",
    "    return 1 - r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train the NN model. There are 8 input neurons. Those are connected to 32 neurons in the hidden (intermediate) layer. Those are in turn connected to a single output neuron.\n",
    "\n",
    "All connections are labelled with weights which are the values that change during training to output the closest result according to the loss function - mean squared error in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(32, activation = lambda x: tf.keras.activations.relu(x, alpha=0.1)),\n",
    "    layers.Dense(16, activation = lambda x: tf.keras.activations.relu(x, alpha=0.1)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "#    loss = keras.losses.MeanSquaredError(),\n",
    "    loss = my_loss,\n",
    "    metrics=[coeff_determination],\n",
    "    optimizer = tf.optimizers.Adam(learning_rate = 0.001)\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    features_train,\n",
    "    labels_train,\n",
    "    epochs=400,\n",
    "    verbose=1,\n",
    "    validation_data = (\n",
    "        features_valid,\n",
    "        labels_valid\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the trained weights labelling the connections of the hidden layer neurons with the output neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].kernel.numpy().transpose()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way to access the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pandas.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a plotter function for the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 500])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the losses: the training set loss and the loss on the validation set. If the loss curve starts to \"dance\" after a few epochs of relative convergence, that means the NN is overfitted on the training data. That is, it becomes too specialised on possible outliers in the training set. That means that outliers in the validation set can get misclassified as a consequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the concrete strength of the set of experiments used for validation. Those experiments weren't used for training, so the predictions shows the performance of the NN on real inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a plotter function for the difference between what was observed in the experiments and what the NN actually computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison():\n",
    "    plt.scatter(labels_valid, labels_predict)\n",
    "#    plt.plot(labels[:,0], y_pred_test, 'r', label='Predicted Data')\n",
    "    plt.xlabel('strength observed in lab')\n",
    "    plt.ylabel('strength predicted by NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the validation concrete strengths alongside the predicted ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = labels_valid.values\n",
    "y_predict = labels_predict.transpose()[0]\n",
    "\n",
    "print('validation values:\\n', y_valid)\n",
    "print('predicted values:\\n', y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R^2 of the validation set. In [1] it was greater than 0.8. Here it is lower because we didn't split the dataset into subsets based on internal correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_valid = R_squared(y_valid, y_predict)\n",
    "print('R^2 of the validation set:', r2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
